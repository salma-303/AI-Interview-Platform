{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11242047,"sourceType":"datasetVersion","datasetId":7023897},{"sourceId":11242818,"sourceType":"datasetVersion","datasetId":7024471}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set Up Gemini API","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:16:04.959018Z","iopub.execute_input":"2025-04-03T23:16:04.959377Z","iopub.status.idle":"2025-04-03T23:16:14.948467Z","shell.execute_reply.started":"2025-04-03T23:16:04.959346Z","shell.execute_reply":"2025-04-03T23:16:14.947111Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:16:15.130709Z","iopub.execute_input":"2025-04-03T23:16:15.131130Z","iopub.status.idle":"2025-04-03T23:16:16.956765Z","shell.execute_reply.started":"2025-04-03T23:16:15.131095Z","shell.execute_reply":"2025-04-03T23:16:16.955443Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:16:20.586593Z","iopub.execute_input":"2025-04-03T23:16:20.587352Z","iopub.status.idle":"2025-04-03T23:16:20.733340Z","shell.execute_reply.started":"2025-04-03T23:16:20.587294Z","shell.execute_reply":"2025-04-03T23:16:20.732066Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Choose a model\n**Best Choice: `gemini-1.5-pro-latest`**\n\nReason:\n\n    - Strong NLP & Reasoning: Best for generating structured interview questions.\n    \n    - Handles Complex Tasks: Can evaluate candidate responses effectively.\n    \n    - Supports Multi-Turn Conversations: Can handle follow-ups dynamically.\n    \n    - Latest Optimizations: Ensures the best performance in Google AI’s Gemini Pro models.\n\n- **Primary Model:** `gemini-1.5-pro-latest` for question generation & response evaluation.\n- **Secondary Option:** `gemini-1.5-flash-latest` if speed is more critical than deep reasoning.\n- **Embedding Model:** `text-embedding-004 if you` need vector-based response analysis.","metadata":{}},{"cell_type":"code","source":"from pprint import pprint\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\nfor model in client.models.list():\n  if model.name == 'models/gemini-1.5-pro-latest':\n    pprint(model.to_json_dict())\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:16:39.694679Z","iopub.execute_input":"2025-04-03T23:16:39.695179Z","iopub.status.idle":"2025-04-03T23:16:40.396733Z","shell.execute_reply.started":"2025-04-03T23:16:39.695138Z","shell.execute_reply":"2025-04-03T23:16:40.395390Z"}},"outputs":[{"name":"stdout","text":"{'description': 'Alias that points to the most recent production '\n                '(non-experimental) release of Gemini 1.5 Pro, our mid-size '\n                'multimodal model that supports up to 2 million tokens.',\n 'display_name': 'Gemini 1.5 Pro Latest',\n 'input_token_limit': 2000000,\n 'name': 'models/gemini-1.5-pro-latest',\n 'output_token_limit': 8192,\n 'supported_actions': ['generateContent', 'countTokens'],\n 'tuned_model_info': {},\n 'version': '001'}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# question generation\n","metadata":{}},{"cell_type":"code","source":"# Define the interview question generation prompt\nprompt = \"\"\"\nYou are an AI interviewer. Generate 5 interview questions for a software developer role \nfocusing on Python, data structures, and problem-solving skills.\n\"\"\"\n\n# Make the API call\nresponse = client.models.generate_content(\n    model='gemini-1.5-pro-latest',\n    contents=prompt)\n\n# Print generated interview questions\nprint(\"\\nInterview Questions:\\n\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:06:34.291801Z","iopub.execute_input":"2025-04-01T15:06:34.292127Z","iopub.status.idle":"2025-04-01T15:06:42.900136Z","shell.execute_reply.started":"2025-04-01T15:06:34.292101Z","shell.execute_reply":"2025-04-01T15:06:42.899065Z"}},"outputs":[{"name":"stdout","text":"\nInterview Questions:\n\n1.  **Scenario:** Imagine you're building a system to track real-time stock prices.  You need to store and quickly retrieve the latest price for thousands of different stock symbols. Which Python data structure would you choose for this task and why?  Explain how you would use it, considering factors like lookup speed and memory efficiency. (Focuses on data structures, Python, and problem-solving related to efficient data retrieval)\n\n\n2.  **Coding Challenge (describe the solution, don't necessarily write code):** You're given a log file containing timestamps and error messages. You need to write a Python function that identifies the most frequent error message within a specific time window (e.g., the last hour).  How would you approach this problem?  What data structures and algorithms would you use to optimize performance, especially with a very large log file?  (Focuses on problem-solving, algorithms, and data structures within a Python context)\n\n\n3.  **Conceptual:** Python offers several ways to implement a queue data structure. Discuss the pros and cons of using a `list` versus the `collections.deque`. In what scenarios would you prefer one over the other?  (Focuses on Python-specific data structures and understanding their tradeoffs)\n\n\n4.  **Debugging/Problem Solving:** You're working with a large Python codebase and notice a memory leak. Describe your strategy for identifying the source of the leak. What tools and techniques would you employ? (Focuses on real-world Python development challenges and problem-solving skills)\n\n\n5.  **Practical Application/Coding (describe the solution):** You have a list of integers.  Write a Python function to find the two numbers that sum up to a given target value.  Discuss the time and space complexity of your solution, and explain how you could optimize it if the list is very large and contains duplicates.  (Focuses on algorithms, problem-solving, and understanding complexity in Python).\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# CV Parsing","metadata":{}},{"cell_type":"code","source":"!pip install pdfplumber docx2txt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:24:27.023546Z","iopub.execute_input":"2025-04-01T15:24:27.023871Z","iopub.status.idle":"2025-04-01T15:24:32.884078Z","shell.execute_reply.started":"2025-04-01T15:24:27.023846Z","shell.execute_reply":"2025-04-01T15:24:32.882793Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting docx2txt\n  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\nCollecting pdfminer.six==20250327 (from pdfplumber)\n  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20250327->pdfplumber) (44.0.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\nDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: docx2txt, pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed docx2txt-0.9 pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"cv_text = \"\"\"John Doe\nSoftware Engineer with 3 years of experience in AI and Computer Vision.\nSkills: Python, OpenCV, TensorFlow, FastAPI.\nExperience: Google - AI Engineer (2021-2024)\"\"\"\n\nprompt = f\"Extract structured information from this CV:\\n{cv_text}\"\nresponse = client.models.generate_content(\n    model='gemini-1.5-pro-latest',\n    contents=prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:24:45.886188Z","iopub.execute_input":"2025-04-01T15:24:45.886635Z","iopub.status.idle":"2025-04-01T15:24:48.035768Z","shell.execute_reply.started":"2025-04-01T15:24:45.886600Z","shell.execute_reply":"2025-04-01T15:24:48.034411Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n  \"name\": \"John Doe\",\n  \"title\": \"Software Engineer\",\n  \"experience_summary\": \"3 years of experience in AI and Computer Vision\",\n  \"skills\": [\"Python\", \"OpenCV\", \"TensorFlow\", \"FastAPI\"],\n  \"experience\": [\n    {\n      \"company\": \"Google\",\n      \"title\": \"AI Engineer\",\n      \"years\": \"2021-2024\"\n    }\n  ]\n}\n```\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pdfplumber\nimport docx2txt\nimport os\n\n# Extract text from PDF\ndef extract_text_from_pdf(pdf_path):\n    text = \"\"\n    with pdfplumber.open(pdf_path) as pdf:\n        for page in pdf.pages:\n            text += page.extract_text() + \"\\n\"\n    return text\n\n# Extract text from DOCX\ndef extract_text_from_docx(docx_path):\n    return docx2txt.process(docx_path)\n\n# Use Gemini API for CV parsing\ndef parse_cv_with_gemini(cv_text):\n    prompt = f\"\"\"\n    Extract key details from the following CV and return structured JSON output.\n    CV Text: {cv_text}\n    \n    Return JSON with keys: \"name\", \"email\", \"phone\", \"education\", \"experience\", \"skills\".\n    \"\"\"\n    response = client.models.generate_content(\n        model='gemini-1.5-pro-latest',\n        contents=prompt)\n    return response.text  # Gemini returns a formatted JSON string\n\n# Main function to process CV\ndef process_cv(file_path, file_type=\"pdf\"):\n    text = extract_text_from_pdf(file_path) if file_type == \"pdf\" else extract_text_from_docx(file_path)\n    parsed_data = parse_cv_with_gemini(text)\n    return parsed_data\n\n# Example usage\ncv_data = process_cv(\"/kaggle/input/resume-dataset/data/data/ENGINEERING/10624813.pdf\", file_type=\"pdf\")\nprint(cv_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:40:27.811230Z","iopub.execute_input":"2025-04-01T15:40:27.811611Z","iopub.status.idle":"2025-04-01T15:40:46.578226Z","shell.execute_reply.started":"2025-04-01T15:40:27.811581Z","shell.execute_reply":"2025-04-01T15:40:46.577386Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n  \"name\": null,\n  \"email\": null,\n  \"phone\": null,\n  \"education\": [\n    {\n      \"degree\": \"Postgraduate courses\",\n      \"major\": \"Cognitive and Neural Systems\",\n      \"university\": \"Boston University\",\n      \"year\": 1991,\n      \"city\": null,\n      \"state\": null\n    },\n    {\n      \"degree\": \"M.S.\",\n      \"major\": \"Computer Science\",\n      \"university\": \"Union College\",\n      \"year\": 1989,\n      \"city\": null,\n      \"state\": null,\n      \"additional_info\": \"Masters Project: A Netless Neural Network - presented on August 16, 1989 at International Conference on Expert Systems and Neural Networks - Theory & Applications\"\n    },\n    {\n      \"degree\": \"B.S.\",\n      \"major\": \"Computer Science\",\n      \"university\": \"Union College\",\n      \"year\": 1988,\n      \"city\": null,\n      \"state\": null\n    }\n  ],\n  \"experience\": [\n    {\n      \"title\": \"Engineering Operations Director\",\n      \"company\": \"Current Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 2014\",\n      \"end_date\": \"Present\",\n      \"description\": \"A high growth company, whose suite of services help researchers successfully communicate their work.\\nIdentified misalignment between technical teams and business, reorganized the technical teams and aligned technical metrics to support business KPIs, increasing revenue and cost savings.\\nDoubled team to 20 people in 4 months, by introducing a new improved hiring process that quickly filtered out non-qualified candidates and increased our acceptance rate to over 90%.\\nAwarded Culture Champion Award.\"\n    },\n    {\n      \"title\": \"Director of Software Development\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 2012\",\n      \"end_date\": \"January 2014\",\n      \"description\": \"A non-profit organization devoted to the advancement and well-being of dogs.\\nTurned around a multiyear software delivery failure, by re-architecting the approach taken, changing the technology used, and transitioning the team to Agile; putting the software back on budget and on time.\\nReduced technical dependency on old technologies by road mapping out a multiyear strategic technology plan, reducing number of technologies used throughout the department by 50%.\\nResponsible for web based PCI compliant e-commerce software, connected to an enterprise database.\"\n    },\n    {\n      \"title\": \"Chief Operating Officer\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 2010\",\n      \"end_date\": \"January 2012\",\n      \"description\": \"Public safety software and services company focused on enterprise-class software for Fire and EMS Departments.\\nImplemented a SaaS solution, allowing smaller towns and cities the ability to use and integrate with the Fire and EMS software.\\nReduced customer's server upgrade time from 4 days to 4 hours.\\nRemoved the requirement, caused by software limitations, that hard mounted mobile computers be removed from fire trucks and brought into the IT dept for upgrades.\\nReduced a mobile computer's install and upgrade times from 1 day per machine to 2 hours.\"\n    },\n        {\n      \"title\": \"Vice President of Engineering\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 2001\",\n      \"end_date\": \"January 2010\",\n      \"description\": \"A mid-sized 3D software company for creating digital models of physical objects, including both 'off-the-shelf' and customized commercial applications.\\nThe software is used globally in markets such as: rapid prototyping, reverse engineering, inspection, and healthcare.\\nGrew revenue from $0 to over $16M with a CAGR greater than 30% for 6 consecutive years.\\nIntegral in receiving 6 term sheets of similar valuation resulting in $8M in VC funds in 2008.\\nExpanded company organically from 22 to 110 employees, coordinated effectively with Sales, Product Development, and Marketing teams to produce globally competitive products.\\nConceived of and implemented critical changes in software architectural designs creating a partner eco- system.\"\n    },\n {\n      \"title\": \"Director of Software Development\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 2000\",\n      \"end_date\": \"January 2001\",\n      \"description\": \"A 30 person company using its patented lens system to project a standard 3D image into a 180 degree hemispherical screen using software to convert the flat image to the curved surface without distortion.\"\n    },\n {\n      \"title\": \"Engineering Manager/Senior Software Engineer\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 1996\",\n      \"end_date\": \"January 2000\",\n      \"description\": \"A 60 person company providing B2B and B2C real-time 3D solutions, via the Internet.\"\n    },\n{\n      \"title\": \"Software Engineer\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 1993\",\n      \"end_date\": \"January 1996\",\n      \"description\": null\n    },\n    {\n      \"title\": \"Software Engineer\",\n      \"company\": \"Company Name\",\n      \"city\": null,\n      \"state\": null,\n      \"start_date\": \"January 1989\",\n      \"end_date\": \"January 1993\",\n      \"description\": null\n    }\n\n  ],\n  \"skills\": [\n    \"3D\",\n    \"Agile\",\n    \"AJAX\",\n    \"C\",\n    \"C++\",\n    \"CSS\",\n    \"HTML\",\n    \"Java\",\n    \"JavaScript\",\n    \"PHP\",\n    \"PL/SQL\",\n    \"Perl\",\n    \"Python\",\n    \"SOAP\",\n    \"SQL\",\n    \"Amazon AWS\",\n    \"Hibernate\",\n    \"EC2\",\n    \"Elastic Search\",\n    \"JSMVC\",\n    \"JUnit\",\n    \"Selenium\",\n    \"CanJS\",\n    \"Aurora\",\n    \"Bootstrap\",\n    \"Jenkins\",\n    \"Oracle\",\n    \"Phabricator\",\n    \"MySQL\",\n    \"GitHub\",\n    \"Camel\",\n    \"Jira\",\n    \"REST\",\n    \"MongoDB\"\n  ]\n}\n```\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Whisper Speech-to-Text (STT) Integration","metadata":{}},{"cell_type":"code","source":"! pip install openai ffmpeg pydub fastapi uvicorn\n!pip install openai-whisper","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:58:30.732278Z","iopub.execute_input":"2025-04-01T15:58:30.732661Z","iopub.status.idle":"2025-04-01T15:58:54.444992Z","shell.execute_reply.started":"2025-04-01T15:58:30.732623Z","shell.execute_reply":"2025-04-01T15:58:54.443822Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: ffmpeg in /usr/local/lib/python3.10/dist-packages (1.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nRequirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.12)\nRequirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.34.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.0a2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.46.1)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.29.0)\nCollecting openai-whisper\n  Downloading openai-whisper-20240930.tar.gz (800 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\nCollecting triton>=2.0.0 (from openai-whisper)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=02ba077153840aa0d6e093a53d8a853d441df188ec6fdf8caba0980c18b974b3\n  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\nSuccessfully built openai-whisper\nInstalling collected packages: triton, openai-whisper\nSuccessfully installed openai-whisper-20240930 triton-3.2.0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import whisper\nprint(\"Whisper Version:\", whisper.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:58:54.446726Z","iopub.execute_input":"2025-04-01T15:58:54.447105Z","iopub.status.idle":"2025-04-01T15:59:00.776012Z","shell.execute_reply.started":"2025-04-01T15:58:54.447066Z","shell.execute_reply":"2025-04-01T15:59:00.775142Z"}},"outputs":[{"name":"stdout","text":"Whisper Version: 20240930\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import torch\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom pydub import AudioSegment\nimport numpy as np\nfrom kaggle_secrets import UserSecretsClient\nimport google.generativeai as genai\nimport time\n\n# Load Whisper model locally\ndef load_whisper_model(model_size=\"base\"):\n    \"\"\"\n    Load Whisper model from Hugging Face transformers.\n    Available sizes: tiny, base, small, medium, large\n    Smaller models are faster but less accurate.\n    \"\"\"\n    print(f\"Loading Whisper {model_size} model...\")\n    processor = WhisperProcessor.from_pretrained(f\"openai/whisper-{model_size}\")\n    model = WhisperForConditionalGeneration.from_pretrained(f\"openai/whisper-{model_size}\")\n    \n    # Move to GPU if available\n    if torch.cuda.is_available():\n        model = model.to(\"cuda\")\n        print(\"Using GPU for inference\")\n    else:\n        print(\"Using CPU for inference\")\n    \n    return model, processor\n\n# Transcribe audio using local Whisper model\ndef transcribe_audio_local(audio_path, model_size=\"base\"):\n    # Load model\n    model, processor = load_whisper_model(model_size)\n    \n    # Load and preprocess audio\n    print(\"Converting audio...\")\n    audio = AudioSegment.from_file(audio_path)\n    # Convert to mono and resample to 16kHz\n    audio = audio.set_channels(1)\n    audio = audio.set_frame_rate(16000)\n    \n    # Convert audio to numpy array\n    audio_array = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0\n    \n    # Process audio\n    print(\"Transcribing...\")\n    start_time = time.time()\n    \n    input_features = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\").input_features\n    if torch.cuda.is_available():\n        input_features = input_features.to(\"cuda\")\n        \n    # Generate tokens and then text\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n    \n    elapsed_time = time.time() - start_time\n    print(f\"Transcription completed in {elapsed_time:.2f} seconds\")\n    \n    return transcription\n\n# Process interview response using Gemini\ndef process_response_with_gemini(transcribed_text):\n    prompt = f\"Analyze this interview response: '{transcribed_text}'. Provide a structured JSON output with key insights.\"\n    \n    response = client.models.generate_content(\n        model='gemini-1.5-pro',\n        contents=prompt\n    )\n    return response.text\n\n# Example usage\ntry:\n    \n    # Choose model size based on your needs:\n    # - \"tiny\" or \"base\" for quick results (less accurate)\n    # - \"small\" for balanced speed/accuracy\n    # - \"medium\" or \"large\" for best accuracy (slower)\n    model_size = \"base\"  # Change as needed\n    \n    transcribed_text = transcribe_audio_local(\n        \"/kaggle/input/sample-response/sample_interview.mp4\", \n        model_size=model_size\n    )\n    print(\"\\nTranscribed Text:\", transcribed_text)\n    \n    ai_analysis = process_response_with_gemini(transcribed_text)\n    print(\"\\nAI Analysis:\", ai_analysis)\nexcept Exception as e:\n    print(f\"Error: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T16:53:47.765862Z","iopub.execute_input":"2025-04-01T16:53:47.766242Z","iopub.status.idle":"2025-04-01T16:54:24.326417Z","shell.execute_reply.started":"2025-04-01T16:53:47.766213Z","shell.execute_reply":"2025-04-01T16:54:24.325488Z"}},"outputs":[{"name":"stdout","text":"Loading Whisper base model...\nUsing CPU for inference\nConverting audio...\nTranscribing...\nTranscription completed in 2.89 seconds\n\nTranscribed Text:  Hello, my name is Salpano Leed and I'm a fresh guide with from the College of Artificial Intelligence. I was measuring an intelligence system robotics and I have hands-on experience as I work on multiple projects during my academic journey.\n\nAI Analysis: ```json\n{\n  \"overall_impression\": \"Needs significant improvement. Grammatical errors and unclear phrasing detract from the message.\",\n  \"strengths\": {\n    \"enthusiasm\": \"Implied enthusiasm by mentioning 'multiple projects' and 'hands-on experience'.\",\n    \"relevant_background\": \"Clearly states a background in AI and robotics.\"\n  },\n  \"weaknesses\": {\n    \"grammar_and_syntax\": [\n      \"Incorrect preposition 'with from'\",\n      \"Unclear phrasing 'measuring an intelligence system robotics'\"\n    ],\n    \"lack_of_specificity\": [\n      \"Doesn't mention specific projects or technologies worked on.\",\n      \"Vague description of role ('measuring an intelligence system robotics').\",\n      \"Doesn't specify the type of 'intelligence system robotics'.\"\n    ],\n    \"weak_opening\": \"Generic opening 'Hello, my name is...' could be more engaging.\"\n  },\n  \"suggested_improvements\": {\n    \"grammar\": \"Correct grammatical errors and use concise language.\",\n    \"clarity\": \"Clearly articulate the role and contributions in projects.\",\n    \"specificity\": \"Provide concrete examples of projects, technologies, and accomplishments.\",\n    \"stronger_opening\": \"Start with a more compelling introduction that highlights a key skill or accomplishment.\",\n    \"rephrased_response_example\": \"Hello, my name is Salpano Leed. I recently graduated from the College of Artificial Intelligence with a focus on intelligent robotics systems.  During my studies, I gained hands-on experience developing [mention specific type of system, e.g., computer vision algorithms for autonomous navigation] through several projects, including [mention 1-2 project titles and briefly describe your role and contributions]. I'm eager to apply my skills and knowledge to [mention target role/area].\"\n  }\n}\n```\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# Sentiment Analysis for Candidate Responses (Bonus Task)","metadata":{}},{"cell_type":"code","source":"response_text = \"I think I would be a good fit for the role, but I am still learning certain aspects.\"\n\nprompt = f\"Analyze the sentiment of this job interview response: '{response_text}'. Classify it as Positive, Neutral, or Negative and provide reasoning.\"\n\nresponse = client.models.generate_content(\n        model='gemini-1.5-pro-latest',\n        contents=prompt)\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:17:00.633397Z","iopub.execute_input":"2025-04-03T23:17:00.633812Z","iopub.status.idle":"2025-04-03T23:17:03.130446Z","shell.execute_reply.started":"2025-04-03T23:17:00.633780Z","shell.execute_reply":"2025-04-03T23:17:03.129493Z"}},"outputs":[{"name":"stdout","text":"The sentiment is **Neutral**.\n\nWhile the candidate expresses interest and a belief in their potential (\"I think I would be a good fit for the role\"), they also acknowledge a skill gap (\"but I am still learning certain aspects\").  The combination of a positive statement with a qualifying statement of a need for further development balances the overall tone to neutral.  They're not overly confident or negative, but realistically self-aware.\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install vaderSentiment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:17:24.412609Z","iopub.execute_input":"2025-04-03T23:17:24.413072Z","iopub.status.idle":"2025-04-03T23:17:29.182996Z","shell.execute_reply.started":"2025-04-03T23:17:24.413037Z","shell.execute_reply":"2025-04-03T23:17:29.181619Z"}},"outputs":[{"name":"stdout","text":"Collecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2025.1.31)\nDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\nanalyzer = SentimentIntensityAnalyzer()\nresponse_text = \"I think I would be a good fit for the role, but I am still learning certain aspects.\"\nsentiment_scores = analyzer.polarity_scores(response_text)\n\nprint(sentiment_scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T23:19:03.029749Z","iopub.execute_input":"2025-04-03T23:19:03.030180Z","iopub.status.idle":"2025-04-03T23:19:03.060196Z","shell.execute_reply.started":"2025-04-03T23:19:03.030148Z","shell.execute_reply":"2025-04-03T23:19:03.058501Z"}},"outputs":[{"name":"stdout","text":"{'neg': 0.0, 'neu': 0.703, 'pos': 0.297, 'compound': 0.6542}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Implement Crew AI Orchestration\\","metadata":{}},{"cell_type":"code","source":"from crewai import Crew, Task, Agent\nfrom langchain_google_genai import GoogleGenerativeAI\n\n\n# Define Agents\ncv_parser = Agent(\n    role=\"CV Parser\",\n    goal=\"Extract key information from resumes\",\n    backstory=\"AI assistant specialized in HR resume processing\",\n    llm=gemini_llm\n)\n\nquestion_generator = Agent(\n    role=\"Interview Question Generator\",\n    goal=\"Generate tailored interview questions based on the parsed CV\",\n    backstory=\"AI trained to generate relevant job interview questions\",\n    llm=gemini_llm\n)\n\nresponse_evaluator = Agent(\n    role=\"Response Evaluator\",\n    goal=\"Analyze and score candidate responses\",\n    backstory=\"AI HR expert evaluating interview responses\",\n    llm=gemini_llm\n)\n\n# Define Tasks\ncv_parsing_task = Task(\n    description=\"Extract key details from resumes and structure them into JSON format.\",\n    agent=cv_parser\n)\n\nquestion_generation_task = Task(\n    description=\"Generate tailored interview questions based on the extracted CV data.\",\n    agent=question_generator\n)\n\nevaluation_task = Task(\n    description=\"Analyze candidate responses and score them based on HR metrics.\",\n    agent=response_evaluator\n)\n\n# Create Crew and Define Workflow\ncrew = Crew(\n    agents=[cv_parser, question_generator, response_evaluator],\n    tasks=[cv_parsing_task, question_generation_task, evaluation_task]\n)\n\n# Execute the Workflow\ncrew.kickoff()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}